## 1. Model_1.py logs:

(.venv) PS C:\Raghu\MyLearnings\ERA_V4\S6-21092025\code\mnist_digits_experiments> python .\Experiment1.py
CUDA Available? True
cuda
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 8, 28, 28]              80
       BatchNorm2d-2            [-1, 8, 28, 28]              16
         MaxPool2d-3            [-1, 8, 14, 14]               0
            Conv2d-4           [-1, 16, 14, 14]           1,168
       BatchNorm2d-5           [-1, 16, 14, 14]              32
         MaxPool2d-6             [-1, 16, 7, 7]               0
            Conv2d-7              [-1, 8, 7, 7]             136
            Conv2d-8             [-1, 32, 7, 7]           2,336
            Conv2d-9             [-1, 28, 7, 7]             924
           Linear-10                   [-1, 10]          13,730
================================================================
Total params: 18,422
Trainable params: 18,422
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.19
Params size (MB): 0.07
Estimated Total Size (MB): 0.26
----------------------------------------------------------------
EPOCH: 1
28092025-1439
Loss=0.09395576268434525 Batch_id=468 Accuracy=90.50: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:32<00:00, 14.52it/s] 
28092025-1439

Test set: Average loss: 0.1156, Accuracy: 9621/10000 (96.21%)

C:\Raghu\MyLearnings\ERA_V4\S6-21092025\code\mnist_digits_experiments\.venv\Lib\site-packages\torch\optim\lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
-----------------------------------------------
EPOCH: 2
28092025-1439
Loss=0.09951924532651901 Batch_id=468 Accuracy=97.21: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:36<00:00, 12.77it/s] 
28092025-1440

Test set: Average loss: 0.0483, Accuracy: 9845/10000 (98.45%)

-----------------------------------------------
EPOCH: 3
28092025-1440
Loss=0.02210957370698452 Batch_id=468 Accuracy=97.92: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:36<00:00, 12.89it/s] 
28092025-1441

Test set: Average loss: 0.0381, Accuracy: 9875/10000 (98.75%)

-----------------------------------------------
EPOCH: 4
28092025-1441
Loss=0.062317878007888794 Batch_id=468 Accuracy=98.27: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:42<00:00, 11.08it/s] 
28092025-1441

Test set: Average loss: 0.0412, Accuracy: 9862/10000 (98.62%)

-----------------------------------------------
EPOCH: 5
28092025-1441
Loss=0.01374585647135973 Batch_id=468 Accuracy=98.54: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:46<00:00, 10.19it/s] 
28092025-1442

Test set: Average loss: 0.0491, Accuracy: 9835/10000 (98.35%)

-----------------------------------------------
EPOCH: 6
28092025-1442
Loss=0.04199260100722313 Batch_id=468 Accuracy=98.67: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:52<00:00,  8.88it/s] 
28092025-1443

Test set: Average loss: 0.0387, Accuracy: 9873/10000 (98.73%)

-----------------------------------------------
EPOCH: 7
28092025-1443
Loss=0.021661289036273956 Batch_id=468 Accuracy=98.78: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:58<00:00,  7.99it/s] 
28092025-1444

Test set: Average loss: 0.0298, Accuracy: 9894/10000 (98.94%)

-----------------------------------------------
EPOCH: 8
28092025-1444
Loss=0.032435160130262375 Batch_id=468 Accuracy=98.90: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:53<00:00,  8.77it/s] 
28092025-1445

Test set: Average loss: 0.0358, Accuracy: 9887/10000 (98.87%)

-----------------------------------------------
EPOCH: 9
28092025-1445
Loss=0.02156253717839718 Batch_id=468 Accuracy=98.92: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:53<00:00,  8.69it/s] 
28092025-1446

Test set: Average loss: 0.0249, Accuracy: 9911/10000 (99.11%)

-----------------------------------------------
EPOCH: 10
28092025-1446
Loss=0.03644905239343643 Batch_id=468 Accuracy=99.00: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:56<00:00,  8.31it/s] 
28092025-1447

Test set: Average loss: 0.0314, Accuracy: 9902/10000 (99.02%)

-----------------------------------------------
EPOCH: 11
28092025-1447
Loss=0.009006721898913383 Batch_id=468 Accuracy=99.10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:20<00:00,  5.85it/s] 
28092025-1449

Test set: Average loss: 0.0279, Accuracy: 9905/10000 (99.05%)

-----------------------------------------------
EPOCH: 12
28092025-1449
Loss=0.002540260786190629 Batch_id=468 Accuracy=99.11: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:04<00:00,  7.25it/s] 
28092025-1450

Test set: Average loss: 0.0267, Accuracy: 9912/10000 (99.12%)

-----------------------------------------------
EPOCH: 13
28092025-1450
Loss=0.008956954814493656 Batch_id=468 Accuracy=99.11: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:04<00:00,  7.30it/s] 
28092025-1451

Test set: Average loss: 0.0268, Accuracy: 9905/10000 (99.05%)

-----------------------------------------------
EPOCH: 14
28092025-1451
Loss=0.02956872247159481 Batch_id=468 Accuracy=99.24: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:00<00:00,  7.81it/s] 
28092025-1452

Test set: Average loss: 0.0309, Accuracy: 9904/10000 (99.04%)

-----------------------------------------------
EPOCH: 15
28092025-1452
Loss=0.03176385536789894 Batch_id=468 Accuracy=99.28: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:44<00:00, 10.48it/s] 
28092025-1453

Test set: Average loss: 0.0265, Accuracy: 9916/10000 (99.16%)

-----------------------------------------------
Plot saved as training_results-28092025-1453.png
(.venv) PS C:\Raghu\MyLearnings\ERA_V4\S6-21092025\code\mnist_digits_experiments> 